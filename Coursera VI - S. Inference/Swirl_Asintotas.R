Recall our simulations and discussions of sample means in previous lessons. We can now talk about the distribution of
| sample means of a collection of iid observations. The mean of the sample mean estimates what?

1: population variance
2: standard error
3: population mean
4: sigma^2/n

Selection: 3

| Your dedication is inspiring!

|======| 5%
| The Law of Large Numbers (LLN) says that the average (mean) approaches what it's estimating. We saw in our
| simulations that the larger the sample size the better the estimation.As we flip a fair coin over and over, it
| eventually converges to the true probability of a head (.5).

...

|========| 7%
| The LLN forms the basis of frequency style thinking.

...

|========= | 8%
| To see this in action, we've copied some code from the slides and created the function coinPlot. It takes an integer
| n which is the number of coin tosses that will be simulated. As coinPlot does these coin flips it computes the
| cumulative sum (assuming heads are 1 and tails 0), but after each toss it divides the cumulative sum by the number of
| flips performed so far. It then plots this value for each of the k=1...n tosses. Try it now for n=10.

> skip()

| Entering the following correct answer for you...

> coinPlot(10)

| All that hard work is paying off!

|=========== |10%
| Your output depends on R's random number generator, but your plot probably jumps around a bit and, by the 10th flip,
| your cumulative sum/10 is probably different from mine. If you did this several times, your plots would vary quite a
| bit. Now call coinPlot again, this time with 10000 as the argument.

> skip()

| Entering the following correct answer for you...

> coinPlot(10000)

| You're the best!

|============|11%
| See the difference? Asymptotics in Action! The line approaches its asymptote of .5. This is the probability you
| expect since what we're plotting, the cumulative sum/number of flips, represents the probability of the coin landing
| on heads. As we know, this is .5 .

...

|==============|12%
| We say that an estimator is CONSISTENT if it converges to what it's trying to estimate. The LLN says that the sample
| mean of iid samples is consistent for the population mean. This is good, right?

...

|=============== |14%
| Based on our previous lesson do you think the sample variance (and hence sample deviation) are consistent as well?

1: Yes
2: No

Selection: 1

| That's correct!

|================= |15%
| Now for something really important - the CENTRAL LIMIT THEOREM (CLT) - one of the most important theorems in all of
| statistics. It states that the distribution of averages of iid variables (properly normalized) becomes that of a
| standard normal as the sample size increases.

...

|==================|16%
| Let's dissect this to see what it means. First, 'properly normalized' means that you transformed the sample mean X'.
| You subtracted the population mean mu from it and divided the difference by sigma/sqrt(n). Here sigma is the standard
| deviation of the population and n is the sample size.

...

|====================|18%
| Second, the CLT says that for large n, this normalized variable, (X'-mu)/(sigma/sqrt(n)) is almost normally
| distributed with mean 0 and variance 1. Remember that n must be large for the CLT to apply.

...

|===================== |19%
| Do you recognize sigma/sqrt(n) from our lesson on variance? Since the population std deviation sigma is unknown,
| sigma/sqrt(n) is often approximated by what?

1: I give up
2: the variance of the population
3: the mean of the population
4: the standard error of the sample mean

Selection: 4

| You are quite good my friend!

|======================= |21%
| Let's rephrase the CLT. Suppose X_1, X_2, ... X_n are independent, identically distributed random variables from an
| infinite population with mean mu and variance sigma^2. Then if n is large, the mean of the X's, call it X', is
| approximately normal with mean mu and variance sigma^2/n. We denote this as X'~N(mu,sigma^2/n).

...

|========================|22%
| To show the CLT in action consider this figure from the slides. It presents 3 histograms of 1000 averages of dice
| rolls with sample sizes of 10, 20 and 30 respectively. Each average of n dice rolls (n=10,20,30) has been normalized
| by subtracting off the mean (3.5) then dividing by the standard error, sqrt(2.92/n). The normalization has made each
| histogram look like a standard normal, i.e., mean 0 and standard deviation 1.

...

|==========================|23%
| Notice that the CLT said nothing about the original population being normally distributed. That's precisely where its
| usefulness lies! We can assume normality of a sample mean no matter what kind of population we have, as long as our
| sample size is large enough and our samples are independent. Let's look at how it works with a binomial experiment
| like flipping a coin.

...

|=========================== |25%
| Recall that if the probability of a head (call it 1) is p, then the probability of a tail (0) is 1-p. The expected
| value then is p and the variance is p-p^2 or p(1-p). Suppose we do n coin flips and let p' represent the average of
| these n flips. We normalize p' by subtracting the mean p and dividing by the std deviation sqrt(p(1-p)/n). Let's do
| this for 1000 trials and plot the resulting histogram.

...

|============================= |26%
| Here's a figure from the slides showing the results of 3 such trials where each trial is for a different value of n
| (10, 20, and 30) and the coin is fair,so E(X)=.5 and the standard error is 1/(2sqrt(n)). Notice how with larger n
| (30) the histogram tightens up around the mean 0.

...

|==============================|27%
| Here's another plot from the slides of the same experiment, this time using a biassed coin. We set the probability of
| a head to .9, so E(X)=.9 and the standard error is sqrt(.09/n) Again, the larger the sample size the more closely the
| distribution looks normal, although with this biassed coin the normal approximation isn't as good as it was with the
| fair coin.

...

|================================|29%
| Now let's talk about confidence intervals.

...

|================================= |30%
| We know from the CLT that for large n, the sample mean is normal with mean mu and standard deviation sigma/sqrt(n).
| We also know that 95% of the area under a normal curve is within two standard deviations of the mean. This figure, a
| standard normal with mu=0 and sigma=1, illustrates this point; the entire shaded portion depicts the area within 2
| standard deviations of the mean and the darker portion shows the 68% of the area within 1 standard deviation.

...

|=================================== |32%
| It follows that 5% of the area under the curve is not shaded. By symmetry of the curve, only 2.5% of the data is
| greater than the mean + 2 standard deviations (mu+2*sigma/sqrt(n)) and only 2.5% is less than the mean - 2 standard
| deviations (mu-2*sigma/sqrt(n)).

...

|====================================|33%
| So the probability that the sample mean X' is bigger than mu + 2sigma/sqrt(n) OR smaller than mu-2sigma/sqrt(n) is
| 5%.Equivalently, the probability of being between these limits is 95%. Of course we could have different sizes of
| intervals. If we wanted something other than 95, then we would use a quantile other than 2.

...

|======================================|34%
| The quantity X' plus or minus 2 sigma/sqrt(n) is called a 95% interval for mu. The 95% says that if one were to
| repeatedly get samples of size n, about 95% of the intervals obtained would contain mu, the quantity we're trying to
| estimate.

...

|======================================= |36%
| Note that for a 95% confidence interval we divide (100-95) by 2 (since we have both left and right tails) and add the
| result to 95 to compute the quantile we need. The 97.5 quantile is actually 1.96, but for simplicity it's often just
| rounded up to 2. If you wanted to find a 90% confidence interval what quantile would you want?

1: 95
2: 100
3: 90
4: 85

Selection: 3

| You're close...I can feel it! Try it again.

| Divide (100-90) by 2 and add this result to 90.

1: 85
2: 95
3: 90
4: 100

Selection: 2

| Great job!

|========================================= |37%
| Use the R function qnorm to find the 95th quantile for a standard normal distribution. Remember that qnorm takes a
| probability as an input. You can use default values for all the other arguments.

> qnorm(0.95)
[1] 1.644854

| You are doing so well!

|==========================================|38%
| As we've seen before, in a binomial distribution in which p represents the probability or proportion of success, the
| variance sigma^2 is p(1-p), so the standard error of the sample mean p' is sqrt(p(1-p)/n) where n is the sample size.
| The 95% confidence interval of p is then p' +/- 2*sqrt(p(1-p)/n). The 2 in this formula represents what?

1: the approximate 97.5% normal quantile
2: the standard error of p'
3: the mean of p'
4: the variance of p'

Selection: 1

| You're the best!

|============================================|40%
| A critical point here is that we don't know the true value of p; that's what we're trying to estimate. How can we
| compute a confidence interval if we don't know p(1-p)? We could be conservative and try to maximize it so we get the
| largest possible confidence interval. Calculus tells us that p(1-p) is maximized when p=1/2, so we get the biggest
| 95% confidence interval when we set p=1/2 in the formula p'+/- 2*sqrt(p(1-p)/n).

...

|============================================= |41%
| Using 1/2 for the value of p in the formula above yields what expression for the 95% confidence interval for p?

1: p'+/- 1/sqrt(n)
2: p'+/- 2*sqrt(n)
3: p'+/- 1/(2*sqrt(n))

Selection: 3

| Try again. Getting it right on the first try is boring anyway!

| p(1-p)=1/4 when p=1/2 and the sqrt(1/4n)=1/(2*sqrt(n)). What happens when you multiply this by 2?

1: p'+/- 1/(2*sqrt(n))
2: p'+/- 1/sqrt(n)
3: p'+/- 2*sqrt(n)

Selection: 1

| That's not the answer I was looking for, but try again.

| p(1-p)=1/4 when p=1/2 and the sqrt(1/4n)=1/(2*sqrt(n)). What happens when you multiply this by 2?

1: p'+/- 1/sqrt(n)
2: p'+/- 1/(2*sqrt(n))
3: p'+/- 2*sqrt(n)

Selection: 2

| Not quite! Try again.

| p(1-p)=1/4 when p=1/2 and the sqrt(1/4n)=1/(2*sqrt(n)). What happens when you multiply this by 2?

1: p'+/- 1/sqrt(n)
2: p'+/- 1/(2*sqrt(n))
3: p'+/- 2*sqrt(n)

Selection: 3

| Not quite right, but keep trying.

| p(1-p)=1/4 when p=1/2 and the sqrt(1/4n)=1/(2*sqrt(n)). What happens when you multiply this by 2?

1: p'+/- 1/(2*sqrt(n))
2: p'+/- 1/sqrt(n)
3: p'+/- 2*sqrt(n)

Selection: 1

| You almost had it, but not quite. Try again.

| p(1-p)=1/4 when p=1/2 and the sqrt(1/4n)=1/(2*sqrt(n)). What happens when you multiply this by 2?

1: p'+/- 1/(2*sqrt(n))
2: p'+/- 1/sqrt(n)
3: p'+/- 2*sqrt(n)

Selection: 2

| Nice work!

|=============================================== |42%
| Here's another example of applying this formula from the slides. Suppose you were running for office and your
| pollster polled 100 people. Of these 60 claimed they were going to vote for you. You'd like to estimate the true
| proportion of people who will vote for you and you want to be 95% confident of your estimate. We need to find the
| limits that will contain the true proportion of your supporters with 95% confidence, so we'll use the formula p' +/-
| 1/sqrt(n) to answer this question. First, what value would you use for p', the sampled estimate?

1: .56
2: .10
3: .60
4: 1.00

Selection: 3

| Perseverance, that's the answer.

|================================================|44%
| What would you use for 1/sqrt(n)?

1: 1/10
2: 1/sqrt(60)
3: 1/100
4: 1/sqrt(56)

Selection: 1

| Great job!

|==================================================|45%
| The bounds of the interval then are what?

1: .46 and .66
2: .55 and .65
3: .5 and .7
4: I haven't a clue

Selection: 3

| Excellent job!

|=================================================== |47%
| How do you feel about the election?

1: confident
2: Perseverance, that's the answer
3: unsure
4: I'll pull out

Selection: 1

| Keep working like that and you'll get there!

|===================================================== |48%
| Another technique for calculating confidence intervals for binomial distributions is to replace p with p'. This is
| called the Wald confidence interval. We can also use the R function qnorm to get a more precise quantile value
| (closer to 1.96) instead of our ballpark estimate of 2.

...

|======================================================|49%
| With the formula p'+/- qnorm(.975)*sqrt(p'(1-p')/100), use the p' and n values from above and the R construct
 | p'+c(-1,1)... to handle the plus/minus portion of the formula. You should see bounds similar to the ones you just
| estimated.

> skip()

| Entering the following correct answer for you...

> .6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)
[1] 0.5039818 0.6960182

| Your dedication is inspiring!

|========================================================|51%
| As an alternative to this Wald interval, we can also use the R function binom.test with the parameters 60 and 100 and
| let all the others default. This function "performs an exact test of a simple null hypothesis about the probability
| of success in a Bernoulli experiment." (This means it guarantees the coverages, uses a lot of computation and doesn't
 | rely on the CLT.) This function returns a lot of information but all we want now are the values of the confidence
| interval that it returns. Use the R construct x$conf.int to find these now.

> skip()

| Entering the following correct answer for you...

> binom.test(60,100)$conf.int
[1] 0.4972092 0.6967052
attr(,"conf.level")
[1] 0.95

| Keep up the great work!

|========================================================= |52%
| Close to what we've seen before, right? Now we're going to see that the Wald interval isn't very accurate when n is
| small. We'll use the example from the slides.

...

|=========================================================== |53%
| Suppose we flip a coin a small number of times, say 20. Also suppose we have a function mywald which takes a
| probability p, and generates 30 sets of 20 coin flips using that probability p. It uses the sampled proportion of
| success, p', for those 20 coin flips to compute the upper and lower bounds of the 95% Wald interval, that is, it
| computes the two numbers p'+/- qnorm(.975) * sqrt(p' * (1-p') / n) for each of the 30 trials. For the given true
| probability p, we count the number of times out of those 30 trials that the true probability p was in the Wald
| confidence interval. We'll call this the coverage.

...

|============================================================|55%
| To make sure you understand what's going on, try running mywald now with the probability .2. It will print out 30 p'
| values (which you don't really need to see), followed by 30 lower bounds, 30 upper bounds and lastly the percentage
| of times that the input .2 was between the two bounds. See if you agree with the percentage you get. Usually it
| suffices to just count the number of times (out of the 30) that .2 is less than the upper bound.

> skip()
[1] "Here are the p' values"
[1] 0.15 0.10 0.25 0.05 0.25 0.25 0.20 0.35 0.15 0.20 0.10 0.20 0.15 0.15 0.20 0.15 0.25 0.15 0.20 0.25 0.05 0.15 0.30
[24] 0.25 0.20 0.25 0.15 0.25 0.35 0.20
[1] "Here are the lower"
[1] -0.006490575 -0.0314783810.060227303 -0.0455168290.0602273030.0602273030.0246954920.140962697
[9] -0.0064905750.024695492 -0.0314783810.024695492 -0.006490575 -0.0064905750.024695492 -0.006490575
[17]0.060227303 -0.0064905750.0246954920.060227303 -0.045516829 -0.0064905750.0991634550.060227303
[25]0.0246954920.060227303 -0.0064905750.0602273030.1409626970.024695492
[1] "Here are the upper"
[1] 0.3064906 0.2314784 0.4397727 0.1455168 0.4397727 0.4397727 0.3753045 0.5590373 0.3064906 0.3753045 0.2314784
[12] 0.3753045 0.3064906 0.3064906 0.3753045 0.3064906 0.4397727 0.3064906 0.3753045 0.4397727 0.1455168 0.3064906
[23] 0.5008365 0.4397727 0.3753045 0.4397727 0.3064906 0.4397727 0.5590373 0.3753045

| Entering the following correct answer for you...

> mywald(.2)
[1] 0.9333333

| You are amazing!

|==============================================================|56%
| Now that you understand the underlying principle, suppose instead of 30 trials, we used 1000 trials. Also suppose we
| did this experiment for a series of probabilities, say from .1 to .9 taking steps of size .05. More specifically,
| we'll call our function using 17 different probabilities, namely .1, .15, .2, .25, ... .9 . We can then plot the
| percentages of coverage for each of the probabilities.

...

|=============================================================== |58%
| Here's the plot of our results. Each of the 17 vertices show the percentage of coverage for a particular true
| probability p passed to the function. Results will vary, but usually the only probability that hits close to or above
| the 95% line is the p=.5 . So this shows that when n, the number of flips, is small (20) the CLT doesn't hold for
| many values of p, so the Wald interval doesn't work very well.

...

|================================================================= |59%
| Let's try the same experiment and increase n, the number of coin flips in each of our 1000 trials, from 20 to 100 to
| see if the plot improves. Again, results may vary, but all the probabilities are much closer to the 95% line, so the
| CLT works better with a bigger value of n.

...

|==================================================================|60%
| A quick fix to the problem of having a small n is to use the Agresti/Coull interval. This simply means we add 2
| successes and 2 failures to the counts when calculating the proportion p'. Specifically, if X is the number of
| successes out of the 20 coin flips, then instead of setting p'=X/20, let p'=(X+2)/24. We use 24 as the number of
| trials since we've added 2 successes and 2 failures to the counts. Note that we still use 20 in the calculation of
| the upper and lower bounds.

...

|====================================================================|62%
| Here's a plot using this Agresti/Coull interval, with 1000 trials of 20 coin flips each. It looks much better than
| both the original Wald with 20 coin flips and the improved Wald with 100 coin flips. However, this technique might
| make the confidence interval too wide.

...

|===================================================================== |63%
| Why does this work? Adding 2 successes and 2 failures pulls p' closer to .5 which, as we saw, is the value which
| maximizes the confidence interval.

...

|======================================================================= |64%
| To show this simply, we wrote a function ACCompar, which takes an integer input n. For each k from 1 to n it computes
| two fractions, k/n and (k+2)/(n+4). It then prints out the boolean vector of whether the new (k+2)/(n+4) fraction is
| less than the old k/n. It also prints out the total number of k's for which the condition is TRUE.

...

|========================================================================|66%
| For all k less than n/2, you see FALSE indicating that the new fraction is greater than or equal to k/n. For all k
| greater than n/2 you see TRUE indicating that the new fraction is less than the old. If k=n/2 the old and new
| fractions are equal.

...

|==========================================================================|67%
| Try running ACCompar now with an input of 20.

> skip()
[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSETRUETRUETRUETRUETRUETRUETRUETRUETRUE
[20]TRUE

| Entering the following correct answer for you...

> ACCompar(20)
[1] 10

| Perseverance, that's the answer.

|=========================================================================== |68%
| Let's move on to Poisson distributions and confidence intervals. Recall that Poisson distributions apply to counts or
| rates. For the latter, we write X~Poisson(lambda*t) where lambda is the expected count per unit of time and t is the
| total monitoring time.

...

|============================================================================= |70%
| Here's another example from the slides. Suppose a nuclear pump failed 5 times out of 94.32 days and we want a 95%
| confidence interval for the failure rate per day. The number of failures X is Poisson distributed with parameter
| (lambda*t). We don't observe the failure rate, but we estimate it as x/t. Call our estimate lambda_hat, so
| lambda_hat=x/t. According to theory, the variance of our estimated failure rate is lambda/t. Again, we don't observe
| lambda, so we use our estimate of it instead. We thus approximate the variance of lambda_hat as lambda_hat/t.

...

|==============================================================================|71%
| In this example what would you use as the estimated mean x/t?

1: 5/94.32
2: 94.32/5
3: I haven't a clue

Selection: 1

| Nice work!

|================================================================================|73%
| Set a variable lamb now with this value.

> skip()

| Entering the following correct answer for you...

> lamb <- 5/94.32

| Keep working like that and you'll get there!

|================================================================================= |74%
| So lamb is our estimated mean and lamb/t is our estimated variance. The formula we've used to calculate a 95%
| confidence interval is est mean + c(-1,1)*qnorm(.975)*sqrt(est var). Use this formula now making the appropriate
| substitutions.

> skip()

| Entering the following correct answer for you...

> lamb +c(-1,1)*qnorm(.975)*sqrt(lamb/94.32)
[1] 0.006545667 0.099476386

| Great job!

|=================================================================================== |75%
| As a check we can use R's function poisson.test with the arguments 5 and 94.32 to check this result. This is an exact
| test so it guarantees coverage. As with the binomial exact test, we only need to look at the conf portion of the
| result using the x$conf construct. Do this now.

> skip()

| Entering the following correct answer for you...

> poisson.test(5,94.32)$conf
[1] 0.01721254 0.12371005
attr(,"conf.level")
[1] 0.95

| Keep up the great work!

|====================================================================================|77%
| Pretty close, right? Now to check the coverage of our estimate we'll run the same simulation experiment we ran before
| with binomial distributions. We'll vary our lambda values from .005 to .1 with steps of .01 (so we have 10 of them),
| and for each one we'll generate 1000 Poisson samples with mean lambda*t. We'll calculate sample means and use them to
| compute 95% confidence intervals. We'll then count how often out of the 1000 simulations the true mean (our lambda)
| was contained in the computed interval.

...

|======================================================================================|78%
| Here's a plot of the results. We see that the coverage improves as lambda gets larger, and it's quite off for small
| lambda values.

...

|======================================================================================= |79%
| Now it's interesting to see how the coverage improves when we increase the unit of time. In the previous plot we used
| t=100 (rounding the 94.32 up). Here's a plot of the same experiment setting t=1000. We see that the coverage is much
| better for almost all the values of lambda, except for the smallest ones.

...

|========================================================================================= |81%
| Now for a quick review!

...

|==========================================================================================|82%
| What tells us that averages of iid samples converge to the population means that they are estimating?

1: the law of large numbers
2: the CLT
3: the BLT
4: the law of small numbers

Selection: 2

| Give it another try.

| Think Big!

1: the law of large numbers
2: the law of small numbers
3: the CLT
4: the BLT

Selection: 1

| You are amazing!

|============================================================================================|84%
| What tells us that averages are approximately normal for large enough sample sizes

1: the law of small numbers
2: the law of large numbers
3: the CLT
4: the BLT

Selection: 3

| Your dedication is inspiring!

|============================================================================================= |85%
| The Central Limit Theorem (CLT) tells us that averages have what kind of distributions?

1: binomial
2: abnormal
3: Poisson
4: normal

Selection: 4

| You nailed it! Good job!

|=============================================================================================== |86%
| The Central Limit Theorem (CLT) tells us that averages have normal distributions centered at what?

1: the population mean
2: the population variance
3: the standard error

Selection: 1

| Your dedication is inspiring!

|================================================================================================|88%
| The Central Limit Theorem (CLT) tells us that averages have normal distributions with standard deviations equal to
| what?

1: the population variance
2: the standard error
3: the population mean

Selection: 2

| You're the best!

|==================================================================================================|89%
| True or False - The Central Limit Theorem (CLT) tells us that averages always have normal distributions no matter how
| big the sample size

1: True
2: False

Selection: 2

| Keep working like that and you'll get there!

|=================================================================================================== |90%
| To calculate a confidence interval for a mean you take the sample mean and add and subtract the relevant normal
| quantile times the what?

1: variance/n
2: variance
3: mean
4: standard error

Selection: 1

| Almost! Try again.

| You want something like a standard deviation, right? Which choice has the word standard in it?

1: variance
2: variance/n
3: standard error
4: mean

Selection: 3

| Excellent work!

|===================================================================================================== |92%
| For a 95% confidence interval approximately how many standard errors would you add and subtract from the sample mean?

1: 6
2: 2
3: 8
4: 4

Selection: 2

| You got it right!

|======================================================================================================|93%
| If you wanted increased coverage what would you do to your confidence interval?

1: keep it the same
2: increase it
3: decrease it

Selection: 2

| You are really on a roll!

|========================================================================================================|95%
| If you had less variability in your data would your confidence interval get bigger or smaller?

1: smaller
2: bigger

Selection: 1

| That's a job well done!

|========================================================================================================= |96%
| If you had larger sample size would your confidence interval get bigger or smaller?

1: bigger
2: smaller

Selection: 1

| Not quite! Try again.

| Recall the size of the confidence interval positively depends on standard error which is sqrt(var/n). If the sample
| size, n, gets bigger the standard error gets smaller and so does the interval.

1: bigger
2: smaller

Selection: 2

| Excellent work!

|=========================================================================================================== |97%
| A quick fix for small sample size binomial calculations is what?

1: changing data seem dishonest
2: add 2 successes and 2 failures
3: add 2 successes and 4 failures
4: add 2 successes and subtract 2 failures

Selection: 3

| You almost had it, but not quite. Try again.

| Adding 2 successes and 2 failures brings the proportion of successes closer to 1/2 which maximizes the confidence
| interval.

1: changing data seem dishonest
2: add 2 successes and 4 failures
3: add 2 successes and subtract 2 failures
4: add 2 successes and 2 failures

Selection: 4

| You are amazing!

|============================================================================================================|99%
| Congrats! You've concluded this lesson on asymptotics. We hope you feel confident and are asymptomatic after going
| through it.
